{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EKvcSs3vR37",
        "outputId": "3bbc46da-a880-4e6e-aa20-52945790f6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytic coefficients valuea are: 1.1696969696969697 1.2363636363636363\n",
            "Gradient descent values are: 1.232718758336947 1.232718758336947\n",
            "Sum Squared Error(SSE) value is: 5.624242424242423\n",
            "R^2 (analytic): 0.952538038613988\n",
            "SSE(gradient descent) value is: 5.624280890666537\n",
            "R^2 (gradient descent) value is: 0.9525377140028141\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "x =np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "y =np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "\n",
        "def regression_analytic(x,y):\n",
        "    n =len(x)\n",
        "    x_mean =np.mean(x)\n",
        "    y_mean =np.mean(y)\n",
        "    g =np.sum((x-x_mean)*(y-y_mean))/np.sum((x-x_mean)**2)\n",
        "    h =y_mean-g*x_mean\n",
        "    return g,h\n",
        "\n",
        "# Gradient descent\n",
        "def l_r_gradient_descent(x, y, learning_rate=0.01, num_iterations=1000):\n",
        "    n = len(x)\n",
        "    g = np.random.rand()\n",
        "    h = np.random.rand()\n",
        "    for _ in range(num_iterations):\n",
        "        y_pred =g * x + h\n",
        "        error =y - y_pred\n",
        "        dm = -2 * np.sum(x * error) / n\n",
        "        db = -2 * np.sum(error) / n\n",
        "        g -=learning_rate * dm\n",
        "        h -=learning_rate * db\n",
        "    return g,h\n",
        "\n",
        "# To Calculate coefficients and performance measures\n",
        "g_analytic,h_analytic =regression_analytic(x, y)\n",
        "g_gradient_descent,h_gradient_descent = l_r_gradient_descent(x, y)\n",
        "\n",
        "# To Calculate The values of SSE and R^2\n",
        "def calculate_sse_r2(x,y,g,h):\n",
        "    y_pred = g * x + h\n",
        "    sse = np.sum((y - y_pred)**2)\n",
        "    sst = np.sum((y - np.mean(y))**2)\n",
        "    r2 = 1 - (sse / sst)\n",
        "    return sse, r2\n",
        "\n",
        "sse_analytic, r2_analytic = calculate_sse_r2(x, y, g_analytic, h_analytic)\n",
        "sse_gradient_descent, r2_gradient_descent = calculate_sse_r2(x,y,g_gradient_descent,h_gradient_descent)\n",
        "\n",
        "# To Print results\n",
        "print(\"Analytic coefficients valuea are:\", g_analytic, h_analytic)\n",
        "print(\"Gradient descent values are:\", h_gradient_descent, h_gradient_descent)\n",
        "print(\"Sum Squared Error(SSE) value is:\", sse_analytic)\n",
        "print(\"R^2 (analytic):\", r2_analytic)\n",
        "print(\"SSE(gradient descent) value is:\", sse_gradient_descent)\n",
        "print(\"R^2 (gradient descent) value is:\", r2_gradient_descent)\n"
      ]
    }
  ]
}